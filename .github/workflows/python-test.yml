name: Python Test

on:
  push:
    branches:
      - main  # Run the workflow when code is pushed to the main branch
      - feature1
  pull_request:
    branches:
      - main  # Run the workflow on pull requests to the main branch

jobs:
  run-python-script:
    runs-on: ubuntu-latest  # Use an Ubuntu runner
    environment: staging
    permissions:
      id-token: write
      contents: read
    steps:
      # Step 1: Checkout the repository
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: Clone scraper repo
      - name: Clone scraper repository
        run: git clone -b test-post-credentials https://github.com/ravilladhaneesh/github-scraper.git

      # - name: Configure aws credentials
      #   uses: aws-actions/configure-aws-credentials@v2
      #   with:
      #     role-to-assume: ${{ secrets.ROLE_ARN}}
      #     aws-region: ${{ secrets.AWS_REGION }}

      # Step 3: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'  # Set Python version (e.g., 3.8, 3.9)

      # Step 4: Set repository name as environment variable
      - name: Set ENV variable with repository name
        run: |
          echo "REPO_NAME=${{ github.repository }}" >> $GITHUB_ENV
          echo "REPO_PATH=${{ github.workspace }}" >> $GITHUB_ENV
          echo "REPO_URL=https://github.com/${{ github.repository }}" >> $GITHUB_ENV
          echo "BRANCH=${{ github.ref_name}}" >> $GITHUB_ENV
          echo "REPO_VISIBILITY=${{ github.event.repository.private }}" >> $GITHUB_ENV
          

      # Step 5: Run the Python script
      - name: Run scraper
        env:
          ROLE_ARN: ${{ secrets.ROLE_ARN }}
        run: |
          pip install -r github-scraper/requirements.txt
          python github-scraper/src/main.py  # This will run the scraper project
